python -u .\train_rec.py --num_epoch 50 --k 3 --dropout 0.5       
D:\IR-Proj-Main\IR_Project\K-domain\DisenCDR\mutils\loader.py:90: SyntaxWarning: "is" with a literal. Did you mean 
"=="?
  if user.get(line[0], "zxczxc") is "zxczxc":
D:\IR-Proj-Main\IR_Project\K-domain\DisenCDR\mutils\loader.py:92: SyntaxWarning: "is" with a literal. Did you mean 
"=="?
  if item.get(line[1], "zxczxc") is "zxczxc":
D:\IR-Proj-Main\IR_Project\K-domain\DisenCDR\mutils\loader.py:108: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if user.get(line[0], "zxczxc") is "zxczxc":
D:\IR-Proj-Main\IR_Project\K-domain\DisenCDR\mutils\loader.py:110: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if item.get(line[1], "zxczxc") is "zxczxc":
D:\IR-Proj-Main\IR_Project\K-domain\DisenCDR\mutils\GraphMaker.py:41: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if user_map.get(line[0], "zxczxc") is "zxczxc":
D:\IR-Proj-Main\IR_Project\K-domain\DisenCDR\mutils\GraphMaker.py:43: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if item_map.get(line[1], "zxczxc") is "zxczxc":
number_user 335
number_item 2593
real graph loaded!
number_user 335
number_item 2356
real graph loaded!
number_user 335
number_item 5868
real graph loaded!
graph fully loaded!
Config saved to file ./saved_models/00/config.json

Running with the following configs:
        k : 3
        model : DisenCDR
        feature_dim : 128
        hidden_dim : 128
        GNN : 2
        dropout : 0.5
        optim : adam
        lr : 0.001
        lr_decay : 0.9
        weight_decay : 0.0005
        decay_epoch : 10
        leakey : 0.1
        cpu : False
        cuda : False
        beta : 0.9
        num_epoch : 50
        batch_size : 1024
        log_step : 200
        log : logs.txt
        save_epoch : 100
        save_dir : ./saved_models
        id : 00
        seed : 2040
        load : False
        model_file : None
        number_user : 335
        number_item : 5868
        model_save_dir : ./saved_models/00


Loading data from ['cell_phones', 'digital', 'movies'] with batch size 1024...
Im here in mutils
Data loaded of train batch
Im here in mutils
Data loaded of dev batch for domain 0
Im here in mutils
Data loaded of dev batch for domain 1
Im here in mutils
Data loaded of dev batch for domain 2
user_num 335
item_num_domain0 2593
train data file0 : 3182, test data file0 : 106
item_num_domain1 2356
train data file1 : 3946, test data file1 : 225
item_num_domain2 5868
train data file2 : 9642, test data file2 : 194
making disencdr
making embeddings
2023-04-20 23:05:40.586745: step 17/850 (epoch 1/50), loss = 1491.463770 (11.443 sec/batch), lr: 0.001000
Evaluating on dev set...
....epoch 1: train_loss = 1491.463770
domain 0 NDCG: 0.0459696946563649 HIT: 0.08490566037735849
domain 1 NDCG: 0.0472292312253297 HIT: 0.12
domain 2 NDCG: 0.0401458913810696 HIT: 0.0979381443298969
0.0459696946563649
new best model saved.

2023-04-20 23:05:58.767476: step 34/850 (epoch 2/50), loss = 1184.194221 (17.648 sec/batch), lr: 0.001000
Evaluating on dev set...
....epoch 2: train_loss = 1184.194221
domain 0 NDCG: 0.03977864210316884 HIT: 0.10377358490566038
domain 1 NDCG: 0.05229779237853377 HIT: 0.12
domain 2 NDCG: 0.036228253624032196 HIT: 0.08247422680412371
0.0459696946563649

2023-04-20 23:06:17.295700: step 51/850 (epoch 3/50), loss = 934.324581 (17.976 sec/batch), lr: 0.001000
Evaluating on dev set...
....epoch 3: train_loss = 934.324581
domain 0 NDCG: 0.03364979196263801 HIT: 0.08490566037735849
domain 1 NDCG: 0.03233174497173433 HIT: 0.08444444444444445
domain 2 NDCG: 0.058145263593768905 HIT: 0.1134020618556701
0.0459696946563649

2023-04-20 23:06:36.287495: step 68/850 (epoch 4/50), loss = 913.011051 (18.439 sec/batch), lr: 0.001000
Evaluating on dev set...
....epoch 4: train_loss = 913.011051
domain 0 NDCG: 0.08783221725072439 HIT: 0.1792452830188679
domain 1 NDCG: 0.03517419607997136 HIT: 0.08
domain 2 NDCG: 0.04369828341872022 HIT: 0.10824742268041238
0.08783221725072439
new best model saved.

2023-04-20 23:06:55.297702: step 85/850 (epoch 5/50), loss = 911.722333 (18.417 sec/batch), lr: 0.001000
Evaluating on dev set...
....epoch 5: train_loss = 911.722333
domain 0 NDCG: 0.06056430248000419 HIT: 0.12264150943396226
domain 1 NDCG: 0.026201871315314824 HIT: 0.07111111111111111
domain 2 NDCG: 0.04906866209634612 HIT: 0.10824742268041238
0.08783221725072439

2023-04-20 23:07:13.934595: step 102/850 (epoch 6/50), loss = 906.271470 (18.097 sec/batch), lr: 0.001000
Evaluating on dev set...
....epoch 6: train_loss = 906.271470
domain 0 NDCG: 0.05062350595488402 HIT: 0.11320754716981132
domain 1 NDCG: 0.058918401581362814 HIT: 0.11555555555555555
domain 2 NDCG: 0.06281412938892106 HIT: 0.13917525773195877
0.08783221725072439

2023-04-20 23:07:39.943849: step 119/850 (epoch 7/50), loss = 906.503648 (25.439 sec/batch), lr: 0.001000
Evaluating on dev set...
....epoch 7: train_loss = 906.503648
domain 0 NDCG: 0.050076413975596895 HIT: 0.08490566037735849
domain 1 NDCG: 0.05776421405551844 HIT: 0.14666666666666667
domain 2 NDCG: 0.02992483940840856 HIT: 0.07216494845360824
0.08783221725072439

2023-04-20 23:08:01.937026: step 136/850 (epoch 8/50), loss = 899.909930 (21.232 sec/batch), lr: 0.001000
Evaluating on dev set...
....epoch 8: train_loss = 899.909930
domain 0 NDCG: 0.05591401838329939 HIT: 0.11320754716981132
domain 1 NDCG: 0.026121055635584083 HIT: 0.06222222222222222
domain 2 NDCG: 0.05217665103754447 HIT: 0.1134020618556701
0.08783221725072439

2023-04-20 23:08:20.404634: step 153/850 (epoch 9/50), loss = 905.315074 (17.737 sec/batch), lr: 0.001000
Evaluating on dev set...
....epoch 9: train_loss = 905.315074
domain 0 NDCG: 0.0318258961484663 HIT: 0.07547169811320754
domain 1 NDCG: 0.052639721201337614 HIT: 0.12444444444444444
domain 2 NDCG: 0.05879083531195994 HIT: 0.13402061855670103
0.08783221725072439

2023-04-20 23:08:49.548646: step 170/850 (epoch 10/50), loss = 898.805890 (28.564 sec/batch), lr: 0.001000
Evaluating on dev set...
....epoch 10: train_loss = 898.805890
domain 0 NDCG: 0.0622400570759036 HIT: 0.12264150943396226
domain 1 NDCG: 0.035576487665800204 HIT: 0.07555555555555556
domain 2 NDCG: 0.03473311028915967 HIT: 0.08762886597938144
0.08783221725072439

2023-04-20 23:09:22.730266: step 187/850 (epoch 11/50), loss = 898.775653 (32.221 sec/batch), lr: 0.001000
Evaluating on dev set...
....epoch 11: train_loss = 898.775653
domain 0 NDCG: 0.031249665217847878 HIT: 0.0660377358490566
domain 1 NDCG: 0.05930741686873072 HIT: 0.10666666666666667
domain 2 NDCG: 0.049585818144796866 HIT: 0.10309278350515463
0.08783221725072439

2023-04-20 23:09:54.799288: step 204/850 (epoch 12/50), loss = 896.336605 (31.180 sec/batch), lr: 0.000900
Evaluating on dev set...
....epoch 12: train_loss = 896.336605
domain 0 NDCG: 0.05321642026439271 HIT: 0.08490566037735849
domain 1 NDCG: 0.042995478478356795 HIT: 0.10222222222222223
domain 2 NDCG: 0.028839018690431865 HIT: 0.08762886597938144
0.08783221725072439

2023-04-20 23:10:32.329615: step 221/850 (epoch 13/50), loss = 895.088386 (35.812 sec/batch), lr: 0.000900
Evaluating on dev set...
....epoch 13: train_loss = 895.088386
domain 0 NDCG: 0.03241040979520356 HIT: 0.07547169811320754
domain 1 NDCG: 0.05353025323654973 HIT: 0.12444444444444444
domain 2 NDCG: 0.045160163560818395 HIT: 0.08762886597938144
0.08783221725072439

2023-04-20 23:10:54.781750: step 238/850 (epoch 14/50), loss = 891.348180 (21.657 sec/batch), lr: 0.000810
Evaluating on dev set...
....epoch 14: train_loss = 891.348180
domain 0 NDCG: 0.03058570364384689 HIT: 0.07547169811320754
domain 1 NDCG: 0.0310429042737568 HIT: 0.08
domain 2 NDCG: 0.044105394924214135 HIT: 0.10309278350515463
0.08783221725072439

2023-04-20 23:11:25.335586: step 255/850 (epoch 15/50), loss = 894.414540 (29.923 sec/batch), lr: 0.000729
Evaluating on dev set...
....epoch 15: train_loss = 894.414540
domain 0 NDCG: 0.029104845685315666 HIT: 0.07547169811320754
domain 1 NDCG: 0.044660987540849906 HIT: 0.10222222222222223
domain 2 NDCG: 0.05072326033207277 HIT: 0.1134020618556701
0.08783221725072439

2023-04-20 23:12:04.277319: step 272/850 (epoch 16/50), loss = 893.503712 (37.759 sec/batch), lr: 0.000656
Evaluating on dev set...
....epoch 16: train_loss = 893.503712
domain 0 NDCG: 0.0478424720255397 HIT: 0.07547169811320754
domain 1 NDCG: 0.04928626609308198 HIT: 0.1111111111111111
domain 2 NDCG: 0.04062049951282908 HIT: 0.0979381443298969
0.08783221725072439

2023-04-20 23:12:26.063655: step 289/850 (epoch 17/50), loss = 895.941194 (20.783 sec/batch), lr: 0.000656
Evaluating on dev set...
....epoch 17: train_loss = 895.941194
domain 0 NDCG: 0.06702471598743459 HIT: 0.14150943396226415
domain 1 NDCG: 0.0504032352520622 HIT: 0.10666666666666667
domain 2 NDCG: 0.057641633139959625 HIT: 0.13402061855670103
0.08783221725072439

2023-04-20 23:13:04.805105: step 306/850 (epoch 18/50), loss = 889.127790 (37.927 sec/batch), lr: 0.000656
Evaluating on dev set...
....epoch 18: train_loss = 889.127790
domain 0 NDCG: 0.024440091431969287 HIT: 0.0660377358490566
domain 1 NDCG: 0.03508345485445889 HIT: 0.08
domain 2 NDCG: 0.03413903186539261 HIT: 0.07216494845360824
0.08783221725072439

2023-04-20 23:13:32.352111: step 323/850 (epoch 19/50), loss = 892.290793 (26.253 sec/batch), lr: 0.000590
Evaluating on dev set...
....epoch 19: train_loss = 892.290793
domain 0 NDCG: 0.04174145994210359 HIT: 0.09433962264150944
domain 1 NDCG: 0.04100509284558511 HIT: 0.08888888888888889
domain 2 NDCG: 0.05236703211911347 HIT: 0.10309278350515463
0.08783221725072439

2023-04-20 23:14:04.803234: step 340/850 (epoch 20/50), loss = 891.203603 (31.832 sec/batch), lr: 0.000590
Evaluating on dev set...
....epoch 20: train_loss = 891.203603
domain 0 NDCG: 0.03146647180274705 HIT: 0.09433962264150944
domain 1 NDCG: 0.054836548451397654 HIT: 0.1111111111111111
domain 2 NDCG: 0.024249086172956194 HIT: 0.05670103092783505
0.08783221725072439

2023-04-20 23:14:39.564338: step 357/850 (epoch 21/50), loss = 891.585711 (31.766 sec/batch), lr: 0.000531
Evaluating on dev set...
....epoch 21: train_loss = 891.585711
domain 0 NDCG: 0.062116927072433346 HIT: 0.10377358490566038
domain 1 NDCG: 0.03954451658373646 HIT: 0.09777777777777778
domain 2 NDCG: 0.052972700553303914 HIT: 0.0979381443298969
0.08783221725072439

2023-04-20 23:15:06.631509: step 374/850 (epoch 22/50), loss = 892.183924 (26.456 sec/batch), lr: 0.000531
Evaluating on dev set...
....epoch 22: train_loss = 892.183924
domain 0 NDCG: 0.036398970076021685 HIT: 0.08490566037735849
domain 1 NDCG: 0.048797338916977066 HIT: 0.12444444444444444
domain 2 NDCG: 0.06993798710243662 HIT: 0.13402061855670103
0.08783221725072439

2023-04-20 23:15:47.171508: step 391/850 (epoch 23/50), loss = 889.338311 (39.216 sec/batch), lr: 0.000478
Evaluating on dev set...
....epoch 23: train_loss = 889.338311
domain 0 NDCG: 0.07115329185411237 HIT: 0.16981132075471697
domain 1 NDCG: 0.04973743345480355 HIT: 0.1111111111111111
domain 2 NDCG: 0.047782961982115214 HIT: 0.10824742268041238
0.08783221725072439

2023-04-20 23:16:11.535145: step 408/850 (epoch 24/50), loss = 892.951499 (23.176 sec/batch), lr: 0.000478
Evaluating on dev set...
....epoch 24: train_loss = 892.951499
domain 0 NDCG: 0.015553889758277893 HIT: 0.02830188679245283
domain 1 NDCG: 0.0511247931022882 HIT: 0.09777777777777778
domain 2 NDCG: 0.02532884630445704 HIT: 0.05670103092783505
0.08783221725072439

2023-04-20 23:16:43.309640: step 425/850 (epoch 25/50), loss = 890.082211 (31.112 sec/batch), lr: 0.000430
Evaluating on dev set...
....epoch 25: train_loss = 890.082211
domain 0 NDCG: 0.060523439598869445 HIT: 0.12264150943396226
domain 1 NDCG: 0.04878674417904796 HIT: 0.10666666666666667
domain 2 NDCG: 0.03201477716651284 HIT: 0.07216494845360824
0.08783221725072439

2023-04-20 23:17:18.550089: step 442/850 (epoch 26/50), loss = 889.062827 (34.180 sec/batch), lr: 0.000430
Evaluating on dev set...
....epoch 26: train_loss = 889.062827
domain 0 NDCG: 0.04119961286001982 HIT: 0.10377358490566038
domain 1 NDCG: 0.03970050305879114 HIT: 0.08444444444444445
domain 2 NDCG: 0.056082478346559654 HIT: 0.12371134020618557
0.08783221725072439

2023-04-20 23:17:48.388213: step 459/850 (epoch 27/50), loss = 889.216380 (28.820 sec/batch), lr: 0.000387
Evaluating on dev set...
....epoch 27: train_loss = 889.216380
domain 0 NDCG: 0.05370229664102843 HIT: 0.11320754716981132
domain 1 NDCG: 0.05637276352893146 HIT: 0.12444444444444444
domain 2 NDCG: 0.046879804898591206 HIT: 0.10309278350515463
0.08783221725072439

2023-04-20 23:18:15.906134: step 476/850 (epoch 28/50), loss = 889.566245 (26.192 sec/batch), lr: 0.000387
Evaluating on dev set...
....epoch 28: train_loss = 889.566245
domain 0 NDCG: 0.0359761558178923 HIT: 0.08490566037735849
domain 1 NDCG: 0.05213757965415239 HIT: 0.1288888888888889
domain 2 NDCG: 0.022822630405350177 HIT: 0.05670103092783505
0.08783221725072439

2023-04-20 23:18:52.953240: step 493/850 (epoch 29/50), loss = 885.538836 (36.346 sec/batch), lr: 0.000349
Evaluating on dev set...
....epoch 29: train_loss = 885.538836
domain 0 NDCG: 0.04032478732868178 HIT: 0.09433962264150944
domain 1 NDCG: 0.04451797870829492 HIT: 0.09333333333333334
domain 2 NDCG: 0.05827500227759095 HIT: 0.13402061855670103
0.08783221725072439

2023-04-20 23:19:31.894056: step 510/850 (epoch 30/50), loss = 885.559405 (37.767 sec/batch), lr: 0.000349
Evaluating on dev set...
....epoch 30: train_loss = 885.559405
domain 0 NDCG: 0.04112965648905284 HIT: 0.10377358490566038
domain 1 NDCG: 0.05668310865378557 HIT: 0.10222222222222223
domain 2 NDCG: 0.05181635192950106 HIT: 0.1134020618556701
0.08783221725072439

2023-04-20 23:20:07.974201: step 527/850 (epoch 31/50), loss = 887.866441 (34.854 sec/batch), lr: 0.000349
Evaluating on dev set...
....epoch 31: train_loss = 887.866441
domain 0 NDCG: 0.029752864220246665 HIT: 0.0660377358490566
domain 1 NDCG: 0.05579026802210715 HIT: 0.09777777777777778
domain 2 NDCG: 0.05868858123155795 HIT: 0.11855670103092783
0.08783221725072439

2023-04-20 23:20:39.420027: step 544/850 (epoch 32/50), loss = 885.528902 (30.809 sec/batch), lr: 0.000314
Evaluating on dev set...
....epoch 32: train_loss = 885.528902
domain 0 NDCG: 0.05901589699684158 HIT: 0.12264150943396226
domain 1 NDCG: 0.03441453483210498 HIT: 0.08
domain 2 NDCG: 0.048712855737242065 HIT: 0.10309278350515463
0.08783221725072439

2023-04-20 23:21:11.329327: step 561/850 (epoch 33/50), loss = 883.696027 (30.668 sec/batch), lr: 0.000314
Evaluating on dev set...
....epoch 33: train_loss = 883.696027
domain 0 NDCG: 0.036902879752734256 HIT: 0.07547169811320754
domain 1 NDCG: 0.05010722248396686 HIT: 0.11555555555555555
domain 2 NDCG: 0.051522754257152775 HIT: 0.12886597938144329
0.08783221725072439

2023-04-20 23:21:40.701250: step 578/850 (epoch 34/50), loss = 887.092673 (28.744 sec/batch), lr: 0.000282
Evaluating on dev set...
....epoch 34: train_loss = 887.092673
domain 0 NDCG: 0.032960761110087 HIT: 0.08490566037735849
domain 1 NDCG: 0.04381698545119201 HIT: 0.08444444444444445
domain 2 NDCG: 0.04022059863669898 HIT: 0.10824742268041238
0.08783221725072439

2023-04-20 23:22:20.374404: step 595/850 (epoch 35/50), loss = 883.541737 (38.366 sec/batch), lr: 0.000254
Evaluating on dev set...
....epoch 35: train_loss = 883.541737
domain 0 NDCG: 0.03153300381582538 HIT: 0.07547169811320754
domain 1 NDCG: 0.03536762681637133 HIT: 0.09777777777777778
domain 2 NDCG: 0.03818517315843205 HIT: 0.07731958762886598
0.08783221725072439

2023-04-20 23:22:42.202041: step 612/850 (epoch 36/50), loss = 882.401080 (21.030 sec/batch), lr: 0.000229
Evaluating on dev set...
....epoch 36: train_loss = 882.401080
domain 0 NDCG: 0.07334284491602512 HIT: 0.14150943396226415
domain 1 NDCG: 0.036787684102356194 HIT: 0.09333333333333334
domain 2 NDCG: 0.041362483477510766 HIT: 0.0979381443298969
0.08783221725072439

2023-04-20 23:23:12.219243: step 629/850 (epoch 37/50), loss = 885.233607 (29.304 sec/batch), lr: 0.000229
Evaluating on dev set...
....epoch 37: train_loss = 885.233607
domain 0 NDCG: 0.05859388776647386 HIT: 0.12264150943396226
domain 1 NDCG: 0.03718187692951179 HIT: 0.08888888888888889
domain 2 NDCG: 0.057436023440933286 HIT: 0.12886597938144329
0.08783221725072439

2023-04-20 23:23:42.723666: step 646/850 (epoch 38/50), loss = 882.644463 (29.382 sec/batch), lr: 0.000206
Evaluating on dev set...
....epoch 38: train_loss = 882.644463
domain 0 NDCG: 0.047081892733354884 HIT: 0.09433962264150944
domain 1 NDCG: 0.04503893091014042 HIT: 0.1111111111111111
domain 2 NDCG: 0.029333504281776158 HIT: 0.05670103092783505
0.08783221725072439

2023-04-20 23:24:12.439088: step 663/850 (epoch 39/50), loss = 879.845574 (29.103 sec/batch), lr: 0.000185
Evaluating on dev set...
....epoch 39: train_loss = 879.845574
domain 0 NDCG: 0.04856687774709398 HIT: 0.10377358490566038
domain 1 NDCG: 0.057606157823490246 HIT: 0.1288888888888889
domain 2 NDCG: 0.05337486816136068 HIT: 0.11855670103092783
0.08783221725072439

2023-04-20 23:24:51.712424: step 680/850 (epoch 40/50), loss = 881.620042 (38.056 sec/batch), lr: 0.000185
Evaluating on dev set...
....epoch 40: train_loss = 881.620042
domain 0 NDCG: 0.05290998767308843 HIT: 0.12264150943396226
domain 1 NDCG: 0.05438744936049258 HIT: 0.1111111111111111
domain 2 NDCG: 0.05600657122714424 HIT: 0.1134020618556701
0.08783221725072439

2023-04-20 23:25:18.363286: step 697/850 (epoch 41/50), loss = 881.966014 (25.573 sec/batch), lr: 0.000185
Evaluating on dev set...
....epoch 41: train_loss = 881.966014
domain 0 NDCG: 0.0330472928031881 HIT: 0.08490566037735849
domain 1 NDCG: 0.04829750782726448 HIT: 0.10222222222222223
domain 2 NDCG: 0.05376591872489147 HIT: 0.1134020618556701
0.08783221725072439

2023-04-20 23:25:54.522539: step 714/850 (epoch 42/50), loss = 883.587704 (34.822 sec/batch), lr: 0.000167
Evaluating on dev set...
....epoch 42: train_loss = 883.587704
domain 0 NDCG: 0.028203266752702124 HIT: 0.08490566037735849
domain 1 NDCG: 0.04516164443204452 HIT: 0.10222222222222223
domain 2 NDCG: 0.034684778353332286 HIT: 0.08762886597938144
0.08783221725072439

2023-04-20 23:26:25.466125: step 731/850 (epoch 43/50), loss = 877.399464 (30.367 sec/batch), lr: 0.000150
Evaluating on dev set...
....epoch 43: train_loss = 877.399464
domain 0 NDCG: 0.020004559600777756 HIT: 0.05660377358490566
domain 1 NDCG: 0.04494661366545037 HIT: 0.10222222222222223
domain 2 NDCG: 0.03369233713781347 HIT: 0.08247422680412371
0.08783221725072439

2023-04-20 23:27:03.830222: step 748/850 (epoch 44/50), loss = 881.669294 (36.794 sec/batch), lr: 0.000135
Evaluating on dev set...
....epoch 44: train_loss = 881.669294
domain 0 NDCG: 0.07724249326310965 HIT: 0.14150943396226415
domain 1 NDCG: 0.047064855276593286 HIT: 0.1111111111111111
domain 2 NDCG: 0.04577123478003142 HIT: 0.1134020618556701
0.08783221725072439

2023-04-20 23:27:38.880916: step 765/850 (epoch 45/50), loss = 882.075529 (34.440 sec/batch), lr: 0.000135
Evaluating on dev set...
....epoch 45: train_loss = 882.075529
domain 0 NDCG: 0.07053057480844309 HIT: 0.1792452830188679
domain 1 NDCG: 0.04553988881573767 HIT: 0.10222222222222223
domain 2 NDCG: 0.05380002189412316 HIT: 0.0979381443298969
0.08783221725072439

2023-04-20 23:28:18.618690: step 782/850 (epoch 46/50), loss = 880.960140 (38.300 sec/batch), lr: 0.000122
Evaluating on dev set...
....epoch 46: train_loss = 880.960140
domain 0 NDCG: 0.05363015607040627 HIT: 0.11320754716981132
domain 1 NDCG: 0.03731747341758311 HIT: 0.09777777777777778
domain 2 NDCG: 0.05197772358363476 HIT: 0.1134020618556701
0.08783221725072439

2023-04-20 23:28:44.549324: step 799/850 (epoch 47/50), loss = 880.522123 (24.760 sec/batch), lr: 0.000109
Evaluating on dev set...
....epoch 47: train_loss = 880.522123
domain 0 NDCG: 0.06156916648197378 HIT: 0.11320754716981132
domain 1 NDCG: 0.048680477698171895 HIT: 0.09777777777777778
domain 2 NDCG: 0.04675368084164582 HIT: 0.1134020618556701
0.08783221725072439

2023-04-20 23:29:24.551429: step 816/850 (epoch 48/50), loss = 878.959896 (39.003 sec/batch), lr: 0.000109
Evaluating on dev set...
....epoch 48: train_loss = 878.959896
domain 0 NDCG: 0.057644463760824945 HIT: 0.14150943396226415
domain 1 NDCG: 0.0527109900599547 HIT: 0.10666666666666667
domain 2 NDCG: 0.044805137132737594 HIT: 0.10824742268041238
0.08783221725072439

2023-04-20 23:29:56.504069: step 833/850 (epoch 49/50), loss = 878.231244 (30.777 sec/batch), lr: 0.000098
Evaluating on dev set...
....epoch 49: train_loss = 878.231244
domain 0 NDCG: 0.048054067285899074 HIT: 0.09433962264150944
domain 1 NDCG: 0.036051120660740926 HIT: 0.08888888888888889
domain 2 NDCG: 0.046576506225807154 HIT: 0.09278350515463918
0.08783221725072439

2023-04-20 23:30:26.351530: step 850/850 (epoch 50/50), loss = 877.729176 (29.246 sec/batch), lr: 0.000089
Evaluating on dev set...
....epoch 50: train_loss = 877.729176
domain 0 NDCG: 0.028083561107120507 HIT: 0.07547169811320754
domain 1 NDCG: 0.039891585819922575 HIT: 0.08888888888888889
domain 2 NDCG: 0.038577939898306296 HIT: 0.09278350515463918
0.08783221725072439

