Loading data from ['cell_phones', 'digital'] with batch size 1024...
Data loaded of train batch
Data loaded of dev batch for domain 0
Data loaded of dev batch for domain 1
user_num 335
item_num_domain0 2593
train data file0 : 3182, test data file0 : 106
item_num_domain1 2356
train data file1 : 3946, test data file1 : 225
making disencdr
making embeddings
2023-04-18 08:44:58.745108: step 7/350 (epoch 1/50), loss = 1314.051915 (2.087 sec/batch), lr: 0.001000
Evaluating on dev set...
...epoch 1: train_loss = 1314.051915
domain 0 NDCG: 0.0693800477057989 HIT: 0.1320754716981132
domain 1 NDCG: 0.041040182750315006 HIT: 0.10222222222222223
0.0693800477057989
new best model saved.

2023-04-18 08:45:02.172808: step 14/350 (epoch 2/50), loss = 1825.112841 (3.134 sec/batch), lr: 0.001000
Evaluating on dev set...
...epoch 2: train_loss = 1825.112841
domain 0 NDCG: 0.045072393200063586 HIT: 0.10377358490566038
domain 1 NDCG: 0.06488434834945192 HIT: 0.14222222222222222
0.0693800477057989

2023-04-18 08:45:05.727220: step 21/350 (epoch 3/50), loss = 1818.571909 (3.239 sec/batch), lr: 0.001000
Evaluating on dev set...
...epoch 3: train_loss = 1818.571909
domain 0 NDCG: 0.044375147404553505 HIT: 0.11320754716981132
domain 1 NDCG: 0.043266751094761455 HIT: 0.10222222222222223
0.0693800477057989

2023-04-18 08:45:09.257784: step 28/350 (epoch 4/50), loss = 1777.903704 (3.219 sec/batch), lr: 0.001000
Evaluating on dev set...
...epoch 4: train_loss = 1777.903704
domain 0 NDCG: 0.05768733128939172 HIT: 0.1320754716981132
domain 1 NDCG: 0.038432968255387036 HIT: 0.09333333333333334
0.0693800477057989

2023-04-18 08:45:12.846253: step 35/350 (epoch 5/50), loss = 1817.678353 (3.282 sec/batch), lr: 0.001000
Evaluating on dev set...
...epoch 5: train_loss = 1817.678353
domain 0 NDCG: 0.056263577539295374 HIT: 0.1320754716981132
domain 1 NDCG: 0.046751374546595816 HIT: 0.10222222222222223
0.0693800477057989

2023-04-18 08:45:16.396048: step 42/350 (epoch 6/50), loss = 1813.903699 (3.241 sec/batch), lr: 0.001000
Evaluating on dev set...
...epoch 6: train_loss = 1813.903699
domain 0 NDCG: 0.020246697937117992 HIT: 0.05660377358490566
domain 1 NDCG: 0.06617434180107196 HIT: 0.13333333333333333
0.0693800477057989

2023-04-18 08:45:19.955790: step 49/350 (epoch 7/50), loss = 1789.277824 (3.245 sec/batch), lr: 0.001000
Evaluating on dev set...
...epoch 7: train_loss = 1789.277824
domain 0 NDCG: 0.03285710741343001 HIT: 0.08490566037735849
domain 1 NDCG: 0.05165477749934979 HIT: 0.10222222222222223
0.0693800477057989

2023-04-18 08:45:23.337743: step 56/350 (epoch 8/50), loss = 1821.107672 (3.088 sec/batch), lr: 0.001000
Evaluating on dev set...
...epoch 8: train_loss = 1821.107672
domain 0 NDCG: 0.03899179996676014 HIT: 0.10377358490566038
domain 1 NDCG: 0.03411628578473609 HIT: 0.08444444444444445
0.0693800477057989

2023-04-18 08:45:26.889587: step 63/350 (epoch 9/50), loss = 1798.919457 (3.233 sec/batch), lr: 0.001000
Evaluating on dev set...
...epoch 9: train_loss = 1798.919457
domain 0 NDCG: 0.038435895832215704 HIT: 0.09433962264150944
domain 1 NDCG: 0.060497062082406856 HIT: 0.1288888888888889
0.0693800477057989

2023-04-18 08:45:30.460032: step 70/350 (epoch 10/50), loss = 1803.845732 (3.262 sec/batch), lr: 0.001000
Evaluating on dev set...
...epoch 10: train_loss = 1803.845732
domain 0 NDCG: 0.04950468636277573 HIT: 0.11320754716981132
domain 1 NDCG: 0.058171788945692 HIT: 0.1288888888888889
0.0693800477057989

2023-04-18 08:45:34.468212: step 77/350 (epoch 11/50), loss = 1800.919148 (3.676 sec/batch), lr: 0.001000
Evaluating on dev set...
...epoch 11: train_loss = 1800.919148
domain 0 NDCG: 0.04863673178761854 HIT: 0.10377358490566038
domain 1 NDCG: 0.05522787497944706 HIT: 0.10666666666666667
0.0693800477057989

2023-04-18 08:45:37.983255: step 84/350 (epoch 12/50), loss = 1804.579597 (3.218 sec/batch), lr: 0.000900
Evaluating on dev set...
...epoch 12: train_loss = 1804.579597
domain 0 NDCG: 0.03657358537881494 HIT: 0.10377358490566038
domain 1 NDCG: 0.04130344515056118 HIT: 0.09777777777777778
0.0693800477057989

2023-04-18 08:45:41.538829: step 91/350 (epoch 13/50), loss = 1793.031250 (3.267 sec/batch), lr: 0.000810
Evaluating on dev set...
...epoch 13: train_loss = 1793.031250
domain 0 NDCG: 0.028589312293562444 HIT: 0.0660377358490566
domain 1 NDCG: 0.048129217761627166 HIT: 0.08444444444444445
0.0693800477057989

2023-04-18 08:45:44.991171: step 98/350 (epoch 14/50), loss = 1815.044328 (3.127 sec/batch), lr: 0.000729
Evaluating on dev set...
...epoch 14: train_loss = 1815.044328
domain 0 NDCG: 0.0229174108186331 HIT: 0.0660377358490566
domain 1 NDCG: 0.040229568450478564 HIT: 0.07555555555555556
0.0693800477057989

2023-04-18 08:45:48.572720: step 105/350 (epoch 15/50), loss = 1806.708473 (3.257 sec/batch), lr: 0.000656
Evaluating on dev set...
...epoch 15: train_loss = 1806.708473
domain 0 NDCG: 0.05419540465062731 HIT: 0.12264150943396226
domain 1 NDCG: 0.04566815800379167 HIT: 0.09333333333333334
0.0693800477057989

2023-04-18 08:45:52.053231: step 112/350 (epoch 16/50), loss = 1821.176606 (3.161 sec/batch), lr: 0.000656
Evaluating on dev set...
...epoch 16: train_loss = 1821.176606
domain 0 NDCG: 0.05911474550724018 HIT: 0.11320754716981132
domain 1 NDCG: 0.043543080104008286 HIT: 0.10222222222222223
0.0693800477057989

2023-04-18 08:45:55.571655: step 119/350 (epoch 17/50), loss = 1781.127779 (3.163 sec/batch), lr: 0.000656
Evaluating on dev set...
...epoch 17: train_loss = 1781.127779
domain 0 NDCG: 0.04470153188851633 HIT: 0.09433962264150944
domain 1 NDCG: 0.04266078699797072 HIT: 0.08
0.0693800477057989

2023-04-18 08:45:59.124934: step 126/350 (epoch 18/50), loss = 1823.802691 (3.246 sec/batch), lr: 0.000590
Evaluating on dev set...
...epoch 18: train_loss = 1823.802691
domain 0 NDCG: 0.03203983807679462 HIT: 0.05660377358490566
domain 1 NDCG: 0.052437960706853505 HIT: 0.13777777777777778
0.0693800477057989

2023-04-18 08:46:02.632168: step 133/350 (epoch 19/50), loss = 1801.420184 (3.178 sec/batch), lr: 0.000531
Evaluating on dev set...
...epoch 19: train_loss = 1801.420184
domain 0 NDCG: 0.04263995759324165 HIT: 0.10377358490566038
domain 1 NDCG: 0.04458306197995024 HIT: 0.08
0.0693800477057989

2023-04-18 08:46:06.194091: step 140/350 (epoch 20/50), loss = 1801.838184 (3.215 sec/batch), lr: 0.000531
Evaluating on dev set...
...epoch 20: train_loss = 1801.838184
domain 0 NDCG: 0.04135245072471424 HIT: 0.08490566037735849
domain 1 NDCG: 0.06456859646873746 HIT: 0.14222222222222222
0.0693800477057989

2023-04-18 08:46:10.383277: step 147/350 (epoch 21/50), loss = 1811.357486 (3.870 sec/batch), lr: 0.000478
Evaluating on dev set...
...epoch 21: train_loss = 1811.357486
domain 0 NDCG: 0.04286142067248714 HIT: 0.10377358490566038
domain 1 NDCG: 0.034671848832213435 HIT: 0.07555555555555556
0.0693800477057989

2023-04-18 08:46:14.320793: step 154/350 (epoch 22/50), loss = 1802.574701 (3.552 sec/batch), lr: 0.000478
Evaluating on dev set...
...epoch 22: train_loss = 1802.574701
domain 0 NDCG: 0.026804166547812033 HIT: 0.0660377358490566
domain 1 NDCG: 0.04120421977503451 HIT: 0.09777777777777778
0.0693800477057989

2023-04-18 08:46:17.794423: step 161/350 (epoch 23/50), loss = 1791.216654 (3.153 sec/batch), lr: 0.000430
Evaluating on dev set...
...epoch 23: train_loss = 1791.216654
domain 0 NDCG: 0.028660823210283327 HIT: 0.08490566037735849
domain 1 NDCG: 0.05100107355668092 HIT: 0.1111111111111111
0.0693800477057989

2023-04-18 08:46:21.344209: step 168/350 (epoch 24/50), loss = 1809.792241 (3.244 sec/batch), lr: 0.000430
Evaluating on dev set...
...epoch 24: train_loss = 1809.792241
domain 0 NDCG: 0.03867226314269837 HIT: 0.10377358490566038
domain 1 NDCG: 0.04533389038724653 HIT: 0.09777777777777778
0.0693800477057989

2023-04-18 08:46:24.835670: step 175/350 (epoch 25/50), loss = 1803.885344 (3.165 sec/batch), lr: 0.000430
Evaluating on dev set...
...epoch 25: train_loss = 1803.885344
domain 0 NDCG: 0.049101074782610374 HIT: 0.10377358490566038
domain 1 NDCG: 0.0358418815084929 HIT: 0.08
0.0693800477057989

2023-04-18 08:46:28.431232: step 182/350 (epoch 26/50), loss = 1788.809489 (3.222 sec/batch), lr: 0.000430
Evaluating on dev set...
...epoch 26: train_loss = 1788.809489
domain 0 NDCG: 0.06395388128330863 HIT: 0.11320754716981132
domain 1 NDCG: 0.030342164961655177 HIT: 0.08
0.0693800477057989

2023-04-18 08:46:32.009624: step 189/350 (epoch 27/50), loss = 1822.964048 (3.239 sec/batch), lr: 0.000430
Evaluating on dev set...
...epoch 27: train_loss = 1822.964048
domain 0 NDCG: 0.046526535268299744 HIT: 0.10377358490566038
domain 1 NDCG: 0.03285456044959626 HIT: 0.08
0.0693800477057989

2023-04-18 08:46:35.532673: step 196/350 (epoch 28/50), loss = 1797.306916 (3.202 sec/batch), lr: 0.000387
Evaluating on dev set...
...epoch 28: train_loss = 1797.306916
domain 0 NDCG: 0.0545874263917133 HIT: 0.11320754716981132
domain 1 NDCG: 0.04683125678978374 HIT: 0.08888888888888889
0.0693800477057989

2023-04-18 08:46:39.345766: step 203/350 (epoch 29/50), loss = 1811.727442 (3.447 sec/batch), lr: 0.000387
Evaluating on dev set...
...epoch 29: train_loss = 1811.727442
domain 0 NDCG: 0.04239362344391467 HIT: 0.11320754716981132
domain 1 NDCG: 0.057720283192808725 HIT: 0.1288888888888889
0.0693800477057989

2023-04-18 08:46:43.040526: step 210/350 (epoch 30/50), loss = 1788.721078 (3.362 sec/batch), lr: 0.000349
Evaluating on dev set...
...epoch 30: train_loss = 1788.721078
domain 0 NDCG: 0.03287575008677852 HIT: 0.07547169811320754
domain 1 NDCG: 0.017856760072717373 HIT: 0.04888888888888889
0.0693800477057989

2023-04-18 08:46:46.548568: step 217/350 (epoch 31/50), loss = 1826.911972 (3.171 sec/batch), lr: 0.000314
Evaluating on dev set...
...epoch 31: train_loss = 1826.911972
domain 0 NDCG: 0.04379507901186554 HIT: 0.08490566037735849
domain 1 NDCG: 0.031811204419965704 HIT: 0.06222222222222222
0.0693800477057989

2023-04-18 08:46:50.139050: step 224/350 (epoch 32/50), loss = 1786.496046 (3.213 sec/batch), lr: 0.000314
Evaluating on dev set...
...epoch 32: train_loss = 1786.496046
domain 0 NDCG: 0.056205125019278074 HIT: 0.10377358490566038
domain 1 NDCG: 0.032399441737101624 HIT: 0.07555555555555556
0.0693800477057989

2023-04-18 08:46:53.727810: step 231/350 (epoch 33/50), loss = 1792.134907 (3.272 sec/batch), lr: 0.000314
Evaluating on dev set...
...epoch 33: train_loss = 1792.134907
domain 0 NDCG: 0.05043716672228731 HIT: 0.09433962264150944
domain 1 NDCG: 0.061564581126136414 HIT: 0.13777777777777778
0.0693800477057989

2023-04-18 08:46:57.462607: step 238/350 (epoch 34/50), loss = 1816.779535 (3.392 sec/batch), lr: 0.000282
Evaluating on dev set...
...epoch 34: train_loss = 1816.779535
domain 0 NDCG: 0.05322904127601648 HIT: 0.10377358490566038
domain 1 NDCG: 0.05801088200905514 HIT: 0.13333333333333333
0.0693800477057989

2023-04-18 08:47:01.104666: step 245/350 (epoch 35/50), loss = 1796.899362 (3.254 sec/batch), lr: 0.000282
Evaluating on dev set...
...epoch 35: train_loss = 1796.899362
domain 0 NDCG: 0.05058847754796241 HIT: 0.10377358490566038
domain 1 NDCG: 0.03679123681565199 HIT: 0.08
0.0693800477057989

2023-04-18 08:47:04.816425: step 252/350 (epoch 36/50), loss = 1786.528747 (3.389 sec/batch), lr: 0.000254
Evaluating on dev set...
...epoch 36: train_loss = 1786.528747
domain 0 NDCG: 0.017888894680568205 HIT: 0.04716981132075472
domain 1 NDCG: 0.057408324814904856 HIT: 0.13333333333333333
0.0693800477057989

2023-04-18 08:47:08.286803: step 259/350 (epoch 37/50), loss = 1812.525397 (3.146 sec/batch), lr: 0.000229
Evaluating on dev set...
...epoch 37: train_loss = 1812.525397
domain 0 NDCG: 0.04055268397902833 HIT: 0.10377358490566038
domain 1 NDCG: 0.05093203840139734 HIT: 0.11555555555555555
0.0693800477057989

2023-04-18 08:47:12.090234: step 266/350 (epoch 38/50), loss = 1808.294649 (3.465 sec/batch), lr: 0.000229
Evaluating on dev set...
...epoch 38: train_loss = 1808.294649
domain 0 NDCG: 0.03229074430169771 HIT: 0.0660377358490566
domain 1 NDCG: 0.03560288986487326 HIT: 0.09333333333333334
0.0693800477057989

2023-04-18 08:47:16.002967: step 273/350 (epoch 39/50), loss = 1815.543025 (3.570 sec/batch), lr: 0.000206
Evaluating on dev set...
...epoch 39: train_loss = 1815.543025
domain 0 NDCG: 0.05372515842364347 HIT: 0.12264150943396226
domain 1 NDCG: 0.033676806664990754 HIT: 0.09333333333333334
0.0693800477057989

2023-04-18 08:47:19.535380: step 280/350 (epoch 40/50), loss = 1823.324066 (3.201 sec/batch), lr: 0.000206
Evaluating on dev set...
...epoch 40: train_loss = 1823.324066
domain 0 NDCG: 0.047756168803086474 HIT: 0.11320754716981132
domain 1 NDCG: 0.026228577984822917 HIT: 0.057777777777777775
0.0693800477057989

2023-04-18 08:47:23.153531: step 287/350 (epoch 41/50), loss = 1804.701119 (3.243 sec/batch), lr: 0.000185
Evaluating on dev set...
...epoch 41: train_loss = 1804.701119
domain 0 NDCG: 0.055226592619311225 HIT: 0.10377358490566038
domain 1 NDCG: 0.06422113325993567 HIT: 0.13333333333333333
0.0693800477057989

2023-04-18 08:47:26.797879: step 294/350 (epoch 42/50), loss = 1820.968601 (3.306 sec/batch), lr: 0.000185
Evaluating on dev set...
...epoch 42: train_loss = 1820.968601
domain 0 NDCG: 0.03495910720475964 HIT: 0.05660377358490566
domain 1 NDCG: 0.05313633188334819 HIT: 0.10666666666666667
0.0693800477057989

2023-04-18 08:47:30.359812: step 301/350 (epoch 43/50), loss = 1796.369198 (3.229 sec/batch), lr: 0.000167
Evaluating on dev set...
...epoch 43: train_loss = 1796.369198
domain 0 NDCG: 0.06351987343448481 HIT: 0.11320754716981132
domain 1 NDCG: 0.03281577110163127 HIT: 0.07555555555555556
0.0693800477057989

2023-04-18 08:47:34.033837: step 308/350 (epoch 44/50), loss = 1830.866347 (3.327 sec/batch), lr: 0.000167
Evaluating on dev set...
...epoch 44: train_loss = 1830.866347
domain 0 NDCG: 0.042269909248042206 HIT: 0.09433962264150944
domain 1 NDCG: 0.05508929182008692 HIT: 0.1111111111111111
0.0693800477057989

2023-04-18 08:47:37.706364: step 315/350 (epoch 45/50), loss = 1804.145994 (3.345 sec/batch), lr: 0.000150
Evaluating on dev set...
...epoch 45: train_loss = 1804.145994
domain 0 NDCG: 0.04979172863539643 HIT: 0.11320754716981132
domain 1 NDCG: 0.05848417697047782 HIT: 0.12444444444444444
0.0693800477057989

2023-04-18 08:47:41.291865: step 322/350 (epoch 46/50), loss = 1811.587667 (3.257 sec/batch), lr: 0.000150
Evaluating on dev set...
...epoch 46: train_loss = 1811.587667
domain 0 NDCG: 0.03138584334163795 HIT: 0.05660377358490566
domain 1 NDCG: 0.04333191246665049 HIT: 0.08888888888888889
0.0693800477057989

2023-04-18 08:47:44.935224: step 329/350 (epoch 47/50), loss = 1831.996047 (3.310 sec/batch), lr: 0.000135
Evaluating on dev set...
...epoch 47: train_loss = 1831.996047
domain 0 NDCG: 0.038632210598748565 HIT: 0.10377358490566038
domain 1 NDCG: 0.04598416996332509 HIT: 0.09777777777777778
0.0693800477057989

2023-04-18 08:47:48.610939: step 336/350 (epoch 48/50), loss = 1810.217185 (3.350 sec/batch), lr: 0.000135
Evaluating on dev set...
...epoch 48: train_loss = 1810.217185
domain 0 NDCG: 0.03511228814586721 HIT: 0.07547169811320754
domain 1 NDCG: 0.03990854060806627 HIT: 0.09333333333333334
0.0693800477057989

2023-04-18 08:47:52.154267: step 343/350 (epoch 49/50), loss = 1831.141762 (3.254 sec/batch), lr: 0.000122
Evaluating on dev set...
...epoch 49: train_loss = 1831.141762
domain 0 NDCG: 0.046500632356284974 HIT: 0.09433962264150944
domain 1 NDCG: 0.06437825153508052 HIT: 0.1111111111111111
0.0693800477057989

2023-04-18 08:47:55.911735: step 350/350 (epoch 50/50), loss = 1814.741824 (3.405 sec/batch), lr: 0.000122
Evaluating on dev set...
...epoch 50: train_loss = 1814.741824
domain 0 NDCG: 0.05620312800713448 HIT: 0.11320754716981132
domain 1 NDCG: 0.03881733470363525 HIT: 0.08444444444444445
0.0693800477057989