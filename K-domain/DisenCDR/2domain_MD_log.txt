Loading data from ['movies', 'digital'] with batch size 1024...
Data loaded of train batch
Data loaded of dev batch for domain 0
Data loaded of dev batch for domain 1
user_num 335
item_num_domain0 5868
train data file0 : 9642, test data file0 : 194
item_num_domain1 2356
train data file1 : 3946, test data file1 : 225
making disencdr
making embeddings
2023-04-18 09:51:28.114375: step 14/700 (epoch 1/50), loss = 1325.534956 (4.985 sec/batch), lr: 0.001000
Evaluating on dev set...
...epoch 1: train_loss = 1325.534956
domain 0 NDCG: 0.03989403651025209 HIT: 0.08762886597938144
domain 1 NDCG: 0.04293069762669151 HIT: 0.09333333333333334
0.03989403651025209
new best model saved.

2023-04-18 09:51:35.881654: step 28/700 (epoch 2/50), loss = 1815.991912 (7.401 sec/batch), lr: 0.001000
Evaluating on dev set...
...epoch 2: train_loss = 1815.991912
domain 0 NDCG: 0.05132556449371715 HIT: 0.11855670103092783
domain 1 NDCG: 0.057363472053674286 HIT: 0.1111111111111111
0.05132556449371715
new best model saved.

2023-04-18 09:51:43.766711: step 42/700 (epoch 3/50), loss = 1802.971865 (7.531 sec/batch), lr: 0.001000
Evaluating on dev set...
...epoch 3: train_loss = 1802.971865
domain 0 NDCG: 0.04308021910671715 HIT: 0.08247422680412371
domain 1 NDCG: 0.06044110486765841 HIT: 0.13333333333333333
0.05132556449371715

2023-04-18 09:51:51.764335: step 56/700 (epoch 4/50), loss = 1813.250772 (7.637 sec/batch), lr: 0.001000
Evaluating on dev set...
...epoch 4: train_loss = 1813.250772
domain 0 NDCG: 0.040094096448840114 HIT: 0.08762886597938144
domain 1 NDCG: 0.06980061781159633 HIT: 0.1511111111111111
0.05132556449371715

2023-04-18 09:52:00.690079: step 70/700 (epoch 5/50), loss = 1799.485606 (8.561 sec/batch), lr: 0.001000
Evaluating on dev set...
...epoch 5: train_loss = 1799.485606
domain 0 NDCG: 0.04044966563316514 HIT: 0.0979381443298969
domain 1 NDCG: 0.05433763686634437 HIT: 0.09333333333333334
0.05132556449371715

2023-04-18 09:52:09.784768: step 84/700 (epoch 6/50), loss = 1805.358045 (8.666 sec/batch), lr: 0.001000
Evaluating on dev set...
...epoch 6: train_loss = 1805.358045
domain 0 NDCG: 0.037502777610923216 HIT: 0.08762886597938144
domain 1 NDCG: 0.040122563791351325 HIT: 0.09333333333333334
0.05132556449371715

2023-04-18 09:52:18.743393: step 98/700 (epoch 7/50), loss = 1797.858953 (8.547 sec/batch), lr: 0.001000
Evaluating on dev set...
...epoch 7: train_loss = 1797.858953
domain 0 NDCG: 0.05832517459495339 HIT: 0.10824742268041238
domain 1 NDCG: 0.05002397434738699 HIT: 0.10222222222222223
0.05832517459495339
new best model saved.

2023-04-18 09:52:28.165724: step 112/700 (epoch 8/50), loss = 1808.441819 (9.000 sec/batch), lr: 0.001000
Evaluating on dev set...
...epoch 8: train_loss = 1808.441819
domain 0 NDCG: 0.04319437989272026 HIT: 0.0979381443298969
domain 1 NDCG: 0.032554925341779374 HIT: 0.08
0.05832517459495339

2023-04-18 09:52:37.951700: step 126/700 (epoch 9/50), loss = 1802.355038 (9.344 sec/batch), lr: 0.001000
Evaluating on dev set...
...epoch 9: train_loss = 1802.355038
domain 0 NDCG: 0.03210927389410186 HIT: 0.08762886597938144
domain 1 NDCG: 0.033152301749849476 HIT: 0.07111111111111111
0.05832517459495339

2023-04-18 09:52:47.795357: step 140/700 (epoch 10/50), loss = 1794.618445 (9.397 sec/batch), lr: 0.001000
Evaluating on dev set...
...epoch 10: train_loss = 1794.618445
domain 0 NDCG: 0.0623549275419516 HIT: 0.13402061855670103
domain 1 NDCG: 0.03149908766124415 HIT: 0.06666666666666667
0.0623549275419516
new best model saved.

2023-04-18 09:52:56.757283: step 154/700 (epoch 11/50), loss = 1806.202736 (8.523 sec/batch), lr: 0.001000
Evaluating on dev set...
...epoch 11: train_loss = 1806.202736
domain 0 NDCG: 0.041408216386711515 HIT: 0.10824742268041238
domain 1 NDCG: 0.05008044960864525 HIT: 0.10222222222222223
0.0623549275419516

2023-04-18 09:53:05.856014: step 168/700 (epoch 12/50), loss = 1793.696711 (8.663 sec/batch), lr: 0.000900
Evaluating on dev set...
...epoch 12: train_loss = 1793.696711
domain 0 NDCG: 0.01135599741102282 HIT: 0.03608247422680412
domain 1 NDCG: 0.04591322777576925 HIT: 0.09777777777777778
0.0623549275419516

2023-04-18 09:53:14.945882: step 182/700 (epoch 13/50), loss = 1832.578808 (8.706 sec/batch), lr: 0.000810
Evaluating on dev set...
...epoch 13: train_loss = 1832.578808
domain 0 NDCG: 0.050148786045925 HIT: 0.12886597938144329
domain 1 NDCG: 0.05102306186811032 HIT: 0.1111111111111111
0.0623549275419516

2023-04-18 09:53:24.267137: step 196/700 (epoch 14/50), loss = 1799.224882 (8.923 sec/batch), lr: 0.000810
Evaluating on dev set...
...epoch 14: train_loss = 1799.224882
domain 0 NDCG: 0.0750665060631494 HIT: 0.13917525773195877
domain 1 NDCG: 0.04369008365502619 HIT: 0.08888888888888889
0.0750665060631494
new best model saved.

2023-04-18 09:53:33.490531: step 210/700 (epoch 15/50), loss = 1788.251053 (8.804 sec/batch), lr: 0.000810
Evaluating on dev set...
...epoch 15: train_loss = 1788.251053
domain 0 NDCG: 0.02718037211042243 HIT: 0.06701030927835051
domain 1 NDCG: 0.03521869947490392 HIT: 0.08444444444444445
0.0750665060631494

2023-04-18 09:53:42.991773: step 224/700 (epoch 16/50), loss = 1818.276512 (9.108 sec/batch), lr: 0.000729
Evaluating on dev set...
...epoch 16: train_loss = 1818.276512
domain 0 NDCG: 0.07889173173933042 HIT: 0.17010309278350516
domain 1 NDCG: 0.03927060421488391 HIT: 0.08
0.07889173173933042
new best model saved.

2023-04-18 09:53:52.999881: step 238/700 (epoch 17/50), loss = 1808.324968 (9.510 sec/batch), lr: 0.000729
Evaluating on dev set...
...epoch 17: train_loss = 1808.324968
domain 0 NDCG: 0.039374533800501536 HIT: 0.09278350515463918
domain 1 NDCG: 0.04066756319533251 HIT: 0.10222222222222223
0.07889173173933042

2023-04-18 09:54:02.922317: step 252/700 (epoch 18/50), loss = 1811.727033 (9.500 sec/batch), lr: 0.000656
Evaluating on dev set...
...epoch 18: train_loss = 1811.727033
domain 0 NDCG: 0.03152189858803464 HIT: 0.08247422680412371
domain 1 NDCG: 0.0485167158929841 HIT: 0.10666666666666667
0.07889173173933042

2023-04-18 09:54:12.755941: step 266/700 (epoch 19/50), loss = 1826.475390 (9.396 sec/batch), lr: 0.000590
Evaluating on dev set...
...epoch 19: train_loss = 1826.475390
domain 0 NDCG: 0.039950390406002435 HIT: 0.09278350515463918
domain 1 NDCG: 0.04611946179605838 HIT: 0.09777777777777778
0.07889173173933042

2023-04-18 09:54:22.786283: step 280/700 (epoch 20/50), loss = 1823.727432 (9.550 sec/batch), lr: 0.000590
Evaluating on dev set...
...epoch 20: train_loss = 1823.727432
domain 0 NDCG: 0.04420424249327185 HIT: 0.10824742268041238
domain 1 NDCG: 0.04385588133847687 HIT: 0.10222222222222223
0.07889173173933042

2023-04-18 09:54:32.502708: step 294/700 (epoch 21/50), loss = 1802.821119 (9.239 sec/batch), lr: 0.000590
Evaluating on dev set...
...epoch 21: train_loss = 1802.821119
domain 0 NDCG: 0.06915547426711187 HIT: 0.15463917525773196
domain 1 NDCG: 0.05281540031791596 HIT: 0.1111111111111111
0.07889173173933042

2023-04-18 09:54:41.753743: step 308/700 (epoch 22/50), loss = 1808.941020 (8.865 sec/batch), lr: 0.000590
Evaluating on dev set...
...epoch 22: train_loss = 1808.941020
domain 0 NDCG: 0.04094299258812935 HIT: 0.09278350515463918
domain 1 NDCG: 0.05717676979091272 HIT: 0.12444444444444444
0.07889173173933042

2023-04-18 09:54:51.112929: step 322/700 (epoch 23/50), loss = 1804.762383 (8.930 sec/batch), lr: 0.000531
Evaluating on dev set...
...epoch 23: train_loss = 1804.762383
domain 0 NDCG: 0.029831200049767168 HIT: 0.08762886597938144
domain 1 NDCG: 0.04533576538336344 HIT: 0.10222222222222223
0.07889173173933042

2023-04-18 09:55:01.266443: step 336/700 (epoch 24/50), loss = 1802.492454 (9.744 sec/batch), lr: 0.000478
Evaluating on dev set...
...epoch 24: train_loss = 1802.492454
domain 0 NDCG: 0.05607065533536166 HIT: 0.10309278350515463
domain 1 NDCG: 0.05021362211367541 HIT: 0.11555555555555555
0.07889173173933042

2023-04-18 09:55:12.570805: step 350/700 (epoch 25/50), loss = 1820.361689 (10.880 sec/batch), lr: 0.000478
Evaluating on dev set...
...epoch 25: train_loss = 1820.361689
domain 0 NDCG: 0.04664369471393152 HIT: 0.09278350515463918
domain 1 NDCG: 0.05139239908801016 HIT: 0.10222222222222223
0.07889173173933042

2023-04-18 09:55:23.136399: step 364/700 (epoch 26/50), loss = 1811.914524 (10.130 sec/batch), lr: 0.000430
Evaluating on dev set...
...epoch 26: train_loss = 1811.914524
domain 0 NDCG: 0.06347981958979615 HIT: 0.15979381443298968
domain 1 NDCG: 0.02958821020623237 HIT: 0.06666666666666667
0.07889173173933042

2023-04-18 09:55:32.602728: step 378/700 (epoch 27/50), loss = 1824.173722 (9.010 sec/batch), lr: 0.000430
Evaluating on dev set...
...epoch 27: train_loss = 1824.173722
domain 0 NDCG: 0.03486375995388133 HIT: 0.08762886597938144
domain 1 NDCG: 0.041127141448153146 HIT: 0.09333333333333334
0.07889173173933042

2023-04-18 09:55:42.088775: step 392/700 (epoch 28/50), loss = 1820.502700 (9.046 sec/batch), lr: 0.000387
Evaluating on dev set...
...epoch 28: train_loss = 1820.502700
domain 0 NDCG: 0.06989960238597252 HIT: 0.14432989690721648
domain 1 NDCG: 0.04741685341274937 HIT: 0.12
0.07889173173933042

2023-04-18 09:55:51.554509: step 406/700 (epoch 29/50), loss = 1801.031405 (9.031 sec/batch), lr: 0.000387
Evaluating on dev set...
...epoch 29: train_loss = 1801.031405
domain 0 NDCG: 0.06676143306541213 HIT: 0.14948453608247422
domain 1 NDCG: 0.06221530488773237 HIT: 0.1288888888888889
0.07889173173933042

2023-04-18 09:56:01.070620: step 420/700 (epoch 30/50), loss = 1821.120813 (9.108 sec/batch), lr: 0.000349
Evaluating on dev set...
...epoch 30: train_loss = 1821.120813
domain 0 NDCG: 0.044240568925878535 HIT: 0.09278350515463918
domain 1 NDCG: 0.04807698816321967 HIT: 0.09777777777777778
0.07889173173933042

2023-04-18 09:56:10.576536: step 434/700 (epoch 31/50), loss = 1792.073293 (9.097 sec/batch), lr: 0.000314
Evaluating on dev set...
...epoch 31: train_loss = 1792.073293
domain 0 NDCG: 0.04565956796655663 HIT: 0.10824742268041238
domain 1 NDCG: 0.03580098027449239 HIT: 0.07555555555555556
0.07889173173933042

2023-04-18 09:56:20.227478: step 448/700 (epoch 32/50), loss = 1786.577545 (9.230 sec/batch), lr: 0.000314
Evaluating on dev set...
...epoch 32: train_loss = 1786.577545
domain 0 NDCG: 0.05042879256188171 HIT: 0.09278350515463918
domain 1 NDCG: 0.05129840698223357 HIT: 0.1111111111111111
0.07889173173933042

2023-04-18 09:56:29.785077: step 462/700 (epoch 33/50), loss = 1808.785893 (9.140 sec/batch), lr: 0.000314
Evaluating on dev set...
...epoch 33: train_loss = 1808.785893
domain 0 NDCG: 0.0353547511676196 HIT: 0.07731958762886598
domain 1 NDCG: 0.04445573809142648 HIT: 0.10666666666666667
0.07889173173933042

2023-04-18 09:56:39.365713: step 476/700 (epoch 34/50), loss = 1789.959965 (9.161 sec/batch), lr: 0.000282
Evaluating on dev set...
...epoch 34: train_loss = 1789.959965
domain 0 NDCG: 0.04486572211242252 HIT: 0.0979381443298969
domain 1 NDCG: 0.039533639604606825 HIT: 0.08888888888888889
0.07889173173933042

2023-04-18 09:56:49.384137: step 490/700 (epoch 35/50), loss = 1802.936619 (9.607 sec/batch), lr: 0.000282
Evaluating on dev set...
...epoch 35: train_loss = 1802.936619
domain 0 NDCG: 0.033049243183162685 HIT: 0.07216494845360824
domain 1 NDCG: 0.04918373336798609 HIT: 0.10222222222222223
0.07889173173933042

2023-04-18 09:56:59.922813: step 504/700 (epoch 36/50), loss = 1824.738496 (10.071 sec/batch), lr: 0.000254
Evaluating on dev set...
...epoch 36: train_loss = 1824.738496
domain 0 NDCG: 0.03932999018705405 HIT: 0.0979381443298969
domain 1 NDCG: 0.03460556970520605 HIT: 0.08
0.07889173173933042

2023-04-18 09:57:10.463516: step 518/700 (epoch 37/50), loss = 1799.083197 (10.090 sec/batch), lr: 0.000254
Evaluating on dev set...
...epoch 37: train_loss = 1799.083197
domain 0 NDCG: 0.04519120184711583 HIT: 0.08762886597938144
domain 1 NDCG: 0.04418300212898179 HIT: 0.09333333333333334
0.07889173173933042

2023-04-18 09:57:21.387729: step 532/700 (epoch 38/50), loss = 1805.479598 (10.477 sec/batch), lr: 0.000254
Evaluating on dev set...
...epoch 38: train_loss = 1805.479598
domain 0 NDCG: 0.049408902847153956 HIT: 0.12371134020618557
domain 1 NDCG: 0.04494097989906676 HIT: 0.1111111111111111
0.07889173173933042

2023-04-18 09:57:32.193909: step 546/700 (epoch 39/50), loss = 1796.570923 (10.327 sec/batch), lr: 0.000254
Evaluating on dev set...
...epoch 39: train_loss = 1796.570923
domain 0 NDCG: 0.02686297203427713 HIT: 0.07216494845360824
domain 1 NDCG: 0.05257371743674884 HIT: 0.11555555555555555
0.07889173173933042

2023-04-18 09:57:42.001457: step 560/700 (epoch 40/50), loss = 1808.791929 (9.377 sec/batch), lr: 0.000229
Evaluating on dev set...
...epoch 40: train_loss = 1808.791929
domain 0 NDCG: 0.03692334624778674 HIT: 0.08762886597938144
domain 1 NDCG: 0.054655247007436944 HIT: 0.1111111111111111
0.07889173173933042

2023-04-18 09:57:51.907366: step 574/700 (epoch 41/50), loss = 1807.296115 (9.482 sec/batch), lr: 0.000229
Evaluating on dev set...
...epoch 41: train_loss = 1807.296115
domain 0 NDCG: 0.04246023697525467 HIT: 0.10309278350515463
domain 1 NDCG: 0.034535097995473545 HIT: 0.08444444444444445
0.07889173173933042

2023-04-18 09:58:05.883522: step 588/700 (epoch 42/50), loss = 1803.076316 (13.492 sec/batch), lr: 0.000229
Evaluating on dev set...
...epoch 42: train_loss = 1803.076316
domain 0 NDCG: 0.03338299167362858 HIT: 0.07216494845360824
domain 1 NDCG: 0.0250252968069937 HIT: 0.06222222222222222
0.07889173173933042

2023-04-18 09:58:17.372838: step 602/700 (epoch 43/50), loss = 1803.239132 (10.362 sec/batch), lr: 0.000206
Evaluating on dev set...
...epoch 43: train_loss = 1803.239132
domain 0 NDCG: 0.0499478754455245 HIT: 0.08762886597938144
domain 1 NDCG: 0.03886255090593423 HIT: 0.08888888888888889
0.07889173173933042

2023-04-18 09:58:27.450090: step 616/700 (epoch 44/50), loss = 1814.942052 (9.654 sec/batch), lr: 0.000206
Evaluating on dev set...
...epoch 44: train_loss = 1814.942052
domain 0 NDCG: 0.04088925061362018 HIT: 0.07731958762886598
domain 1 NDCG: 0.04225282911031773 HIT: 0.09333333333333334
0.07889173173933042

2023-04-18 09:58:37.406758: step 630/700 (epoch 45/50), loss = 1815.880497 (9.515 sec/batch), lr: 0.000185
Evaluating on dev set...
...epoch 45: train_loss = 1815.880497
domain 0 NDCG: 0.05358744922121348 HIT: 0.10309278350515463
domain 1 NDCG: 0.03100074201073105 HIT: 0.05333333333333334
0.07889173173933042

2023-04-18 09:58:47.354084: step 644/700 (epoch 46/50), loss = 1815.738578 (9.512 sec/batch), lr: 0.000185
Evaluating on dev set...
...epoch 46: train_loss = 1815.738578
domain 0 NDCG: 0.031713520494834564 HIT: 0.07216494845360824
domain 1 NDCG: 0.04670029022474308 HIT: 0.10222222222222223
0.07889173173933042

2023-04-18 09:58:57.326316: step 658/700 (epoch 47/50), loss = 1789.295244 (9.535 sec/batch), lr: 0.000167
Evaluating on dev set...
...epoch 47: train_loss = 1789.295244
domain 0 NDCG: 0.04648500177254253 HIT: 0.08762886597938144
domain 1 NDCG: 0.03836495041992099 HIT: 0.07555555555555556
0.07889173173933042

2023-04-18 09:59:07.569802: step 672/700 (epoch 48/50), loss = 1798.634053 (9.798 sec/batch), lr: 0.000167
Evaluating on dev set...
...epoch 48: train_loss = 1798.634053
domain 0 NDCG: 0.04964420408914361 HIT: 0.10824742268041238
domain 1 NDCG: 0.04137045540271813 HIT: 0.09333333333333334
0.07889173173933042

2023-04-18 09:59:17.653620: step 686/700 (epoch 49/50), loss = 1819.272937 (9.653 sec/batch), lr: 0.000167
Evaluating on dev set...
...epoch 49: train_loss = 1819.272937
domain 0 NDCG: 0.031849851627326765 HIT: 0.07731958762886598
domain 1 NDCG: 0.05945589692127515 HIT: 0.1288888888888889
0.07889173173933042

2023-04-18 09:59:27.647779: step 700/700 (epoch 50/50), loss = 1812.722182 (9.546 sec/batch), lr: 0.000150
Evaluating on dev set...
...epoch 50: train_loss = 1812.722182
domain 0 NDCG: 0.03618576412258345 HIT: 0.08762886597938144
domain 1 NDCG: 0.0463723735239814 HIT: 0.10222222222222223
0.07889173173933042