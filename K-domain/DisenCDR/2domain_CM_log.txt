Loading data from ['cell_phones', 'movies'] with batch size 1024...
Data loaded of train batch
Data loaded of dev batch for domain 0
Data loaded of dev batch for domain 1
user_num 335
item_num_domain0 2593
train data file0 : 3182, test data file0 : 106
item_num_domain1 5868
train data file1 : 9642, test data file1 : 194
making disencdr
making embeddings
2023-04-18 08:56:24.780054: step 13/650 (epoch 1/50), loss = 1330.734197 (5.967 sec/batch), lr: 0.001000
Evaluating on dev set...
..epoch 1: train_loss = 1330.734197
domain 0 NDCG: 0.06931106745081486 HIT: 0.1320754716981132
domain 1 NDCG: 0.0326908151160275 HIT: 0.08247422680412371
0.06931106745081486
new best model saved.

2023-04-18 08:56:34.443621: step 26/650 (epoch 2/50), loss = 1802.956179 (9.235 sec/batch), lr: 0.001000
Evaluating on dev set...
..epoch 2: train_loss = 1802.956179
domain 0 NDCG: 0.05760800793297398 HIT: 0.1320754716981132
domain 1 NDCG: 0.02518030674827485 HIT: 0.05154639175257732
0.06931106745081486

2023-04-18 08:56:44.370945: step 39/650 (epoch 3/50), loss = 1806.247500 (9.437 sec/batch), lr: 0.001000
Evaluating on dev set...
..epoch 3: train_loss = 1806.247500
domain 0 NDCG: 0.04938265628962875 HIT: 0.07547169811320754
domain 1 NDCG: 0.04835567102409453 HIT: 0.10309278350515463
0.06931106745081486

2023-04-18 08:56:54.285695: step 52/650 (epoch 4/50), loss = 1826.247083 (9.423 sec/batch), lr: 0.001000
Evaluating on dev set...
..epoch 4: train_loss = 1826.247083
domain 0 NDCG: 0.07832970880618498 HIT: 0.1509433962264151
domain 1 NDCG: 0.042552206128837 HIT: 0.08762886597938144
0.07832970880618498
new best model saved.

2023-04-18 08:57:04.119894: step 65/650 (epoch 5/50), loss = 1818.462961 (9.338 sec/batch), lr: 0.001000
Evaluating on dev set...
..epoch 5: train_loss = 1818.462961
domain 0 NDCG: 0.0799607998252873 HIT: 0.1509433962264151
domain 1 NDCG: 0.03857750859481326 HIT: 0.08762886597938144
0.0799607998252873
new best model saved.

2023-04-18 08:57:14.041706: step 78/650 (epoch 6/50), loss = 1801.670722 (9.435 sec/batch), lr: 0.001000
Evaluating on dev set...
..epoch 6: train_loss = 1801.670722
domain 0 NDCG: 0.044166009081191636 HIT: 0.09433962264150944
domain 1 NDCG: 0.044327191004773114 HIT: 0.10824742268041238
0.0799607998252873

2023-04-18 08:57:25.779210: step 91/650 (epoch 7/50), loss = 1814.893623 (11.277 sec/batch), lr: 0.001000
Evaluating on dev set...
..epoch 7: train_loss = 1814.893623
domain 0 NDCG: 0.060174193332291556 HIT: 0.12264150943396226
domain 1 NDCG: 0.034780591907523674 HIT: 0.08762886597938144
0.0799607998252873

2023-04-18 08:57:35.752215: step 104/650 (epoch 8/50), loss = 1812.208545 (9.478 sec/batch), lr: 0.001000
Evaluating on dev set...
..epoch 8: train_loss = 1812.208545
domain 0 NDCG: 0.07894636523285833 HIT: 0.1509433962264151
domain 1 NDCG: 0.03566622384414961 HIT: 0.09278350515463918
0.0799607998252873

2023-04-18 08:57:45.654043: step 117/650 (epoch 9/50), loss = 1799.608720 (9.456 sec/batch), lr: 0.001000
Evaluating on dev set...
..epoch 9: train_loss = 1799.608720
domain 0 NDCG: 0.01998640906577279 HIT: 0.03773584905660377
domain 1 NDCG: 0.04247453417860159 HIT: 0.08247422680412371
0.0799607998252873

2023-04-18 08:57:56.687783: step 130/650 (epoch 10/50), loss = 1785.547887 (10.585 sec/batch), lr: 0.001000
Evaluating on dev set...
..epoch 10: train_loss = 1785.547887
domain 0 NDCG: 0.057251951832705684 HIT: 0.11320754716981132
domain 1 NDCG: 0.03206145220524417 HIT: 0.07216494845360824
0.0799607998252873

2023-04-18 08:58:13.407766: step 143/650 (epoch 11/50), loss = 1805.822991 (16.193 sec/batch), lr: 0.001000
Evaluating on dev set...
..epoch 11: train_loss = 1805.822991
domain 0 NDCG: 0.04229233463019654 HIT: 0.10377358490566038
domain 1 NDCG: 0.06639070835745632 HIT: 0.14432989690721648
0.0799607998252873

2023-04-18 08:58:24.137493: step 156/650 (epoch 12/50), loss = 1815.994905 (10.275 sec/batch), lr: 0.000900
Evaluating on dev set...
..epoch 12: train_loss = 1815.994905
domain 0 NDCG: 0.03649565655198437 HIT: 0.07547169811320754
domain 1 NDCG: 0.056181628212774073 HIT: 0.10309278350515463
0.0799607998252873

2023-04-18 08:58:34.606655: step 169/650 (epoch 13/50), loss = 1831.654912 (10.027 sec/batch), lr: 0.000810
Evaluating on dev set...
..epoch 13: train_loss = 1831.654912
domain 0 NDCG: 0.0486343851196496 HIT: 0.10377358490566038
domain 1 NDCG: 0.04347690542564714 HIT: 0.0979381443298969
0.0799607998252873

2023-04-18 08:58:45.183309: step 182/650 (epoch 14/50), loss = 1809.168216 (10.084 sec/batch), lr: 0.000810
Evaluating on dev set...
..epoch 14: train_loss = 1809.168216
domain 0 NDCG: 0.04419507057965225 HIT: 0.11320754716981132
domain 1 NDCG: 0.04214718340300004 HIT: 0.07731958762886598
0.0799607998252873

2023-04-18 08:58:55.698173: step 195/650 (epoch 15/50), loss = 1823.021254 (10.039 sec/batch), lr: 0.000729
Evaluating on dev set...
..epoch 15: train_loss = 1823.021254
domain 0 NDCG: 0.05257358856291707 HIT: 0.1320754716981132
domain 1 NDCG: 0.055814420563828786 HIT: 0.11855670103092783
0.0799607998252873

2023-04-18 08:59:06.214861: step 208/650 (epoch 16/50), loss = 1813.201149 (10.018 sec/batch), lr: 0.000729
Evaluating on dev set...
..epoch 16: train_loss = 1813.201149
domain 0 NDCG: 0.04162777064882343 HIT: 0.09433962264150944
domain 1 NDCG: 0.055424630261559214 HIT: 0.11855670103092783
0.0799607998252873

2023-04-18 08:59:16.993212: step 221/650 (epoch 17/50), loss = 1830.853825 (10.312 sec/batch), lr: 0.000656
Evaluating on dev set...
..epoch 17: train_loss = 1830.853825
domain 0 NDCG: 0.05359437837360583 HIT: 0.11320754716981132
domain 1 NDCG: 0.05663718310684657 HIT: 0.12371134020618557
0.0799607998252873

2023-04-18 08:59:27.612410: step 234/650 (epoch 18/50), loss = 1814.039638 (10.149 sec/batch), lr: 0.000656
Evaluating on dev set...
..epoch 18: train_loss = 1814.039638
domain 0 NDCG: 0.07047955676989191 HIT: 0.1320754716981132
domain 1 NDCG: 0.06205237032642255 HIT: 0.11855670103092783
0.0799607998252873

2023-04-18 08:59:38.415020: step 247/650 (epoch 19/50), loss = 1799.071624 (10.316 sec/batch), lr: 0.000656
Evaluating on dev set...
..epoch 19: train_loss = 1799.071624
domain 0 NDCG: 0.04926595447265194 HIT: 0.10377358490566038
domain 1 NDCG: 0.05758164440220529 HIT: 0.12371134020618557
0.0799607998252873

2023-04-18 08:59:49.126049: step 260/650 (epoch 20/50), loss = 1828.878167 (10.228 sec/batch), lr: 0.000590
Evaluating on dev set...
..epoch 20: train_loss = 1828.878167
domain 0 NDCG: 0.032635186963309123 HIT: 0.08490566037735849
domain 1 NDCG: 0.05410190170207524 HIT: 0.13402061855670103
0.0799607998252873

2023-04-18 08:59:59.316645: step 273/650 (epoch 21/50), loss = 1821.615281 (9.724 sec/batch), lr: 0.000531
Evaluating on dev set...
..epoch 21: train_loss = 1821.615281
domain 0 NDCG: 0.03461777070219546 HIT: 0.0660377358490566
domain 1 NDCG: 0.0493045528731312 HIT: 0.11855670103092783
0.0799607998252873

2023-04-18 09:00:08.820528: step 286/650 (epoch 22/50), loss = 1793.241001 (9.073 sec/batch), lr: 0.000531
Evaluating on dev set...
..epoch 22: train_loss = 1793.241001
domain 0 NDCG: 0.03704777797772298 HIT: 0.09433962264150944
domain 1 NDCG: 0.04504012277175334 HIT: 0.08247422680412371
0.0799607998252873

2023-04-18 09:00:18.575276: step 299/650 (epoch 23/50), loss = 1809.526996 (9.303 sec/batch), lr: 0.000531
Evaluating on dev set...
..epoch 23: train_loss = 1809.526996
domain 0 NDCG: 0.030297256565255264 HIT: 0.08490566037735849
domain 1 NDCG: 0.03966858364892607 HIT: 0.08247422680412371
0.0799607998252873

2023-04-18 09:00:29.125452: step 312/650 (epoch 24/50), loss = 1825.586978 (10.050 sec/batch), lr: 0.000478
Evaluating on dev set...
..epoch 24: train_loss = 1825.586978
domain 0 NDCG: 0.04020034182978699 HIT: 0.09433962264150944
domain 1 NDCG: 0.04751077800382872 HIT: 0.10309278350515463
0.0799607998252873

2023-04-18 09:00:39.923154: step 325/650 (epoch 25/50), loss = 1788.711476 (10.328 sec/batch), lr: 0.000478
Evaluating on dev set...
..epoch 25: train_loss = 1788.711476
domain 0 NDCG: 0.05132578089354786 HIT: 0.11320754716981132
domain 1 NDCG: 0.04147387427668971 HIT: 0.09278350515463918
0.0799607998252873

2023-04-18 09:00:50.529226: step 338/650 (epoch 26/50), loss = 1819.082179 (10.097 sec/batch), lr: 0.000478
Evaluating on dev set...
..epoch 26: train_loss = 1819.082179
domain 0 NDCG: 0.06063949347179075 HIT: 0.1509433962264151
domain 1 NDCG: 0.04728745313856936 HIT: 0.11855670103092783
0.0799607998252873

2023-04-18 09:01:01.092487: step 351/650 (epoch 27/50), loss = 1823.006019 (10.078 sec/batch), lr: 0.000478
Evaluating on dev set...
..epoch 27: train_loss = 1823.006019
domain 0 NDCG: 0.03378621952749063 HIT: 0.09433962264150944
domain 1 NDCG: 0.03304815244554608 HIT: 0.08247422680412371
0.0799607998252873

2023-04-18 09:01:12.878867: step 364/650 (epoch 28/50), loss = 1833.759929 (11.309 sec/batch), lr: 0.000430
Evaluating on dev set...
..epoch 28: train_loss = 1833.759929
domain 0 NDCG: 0.02661499666960698 HIT: 0.05660377358490566
domain 1 NDCG: 0.048319600110093334 HIT: 0.10309278350515463
0.0799607998252873

2023-04-18 09:01:25.269466: step 377/650 (epoch 29/50), loss = 1794.618781 (11.802 sec/batch), lr: 0.000387
Evaluating on dev set...
..epoch 29: train_loss = 1794.618781
domain 0 NDCG: 0.054835609686058065 HIT: 0.12264150943396226
domain 1 NDCG: 0.041606678935649816 HIT: 0.08247422680412371
0.0799607998252873

2023-04-18 09:01:36.646414: step 390/650 (epoch 30/50), loss = 1819.833628 (10.860 sec/batch), lr: 0.000387
Evaluating on dev set...
..epoch 30: train_loss = 1819.833628
domain 0 NDCG: 0.041077498368102615 HIT: 0.11320754716981132
domain 1 NDCG: 0.03743147014444686 HIT: 0.08247422680412371
0.0799607998252873

2023-04-18 09:01:47.482083: step 403/650 (epoch 31/50), loss = 1853.005293 (10.350 sec/batch), lr: 0.000349
Evaluating on dev set...
..epoch 31: train_loss = 1853.005293
domain 0 NDCG: 0.041189338516364984 HIT: 0.0660377358490566
domain 1 NDCG: 0.042102500067796034 HIT: 0.10309278350515463
0.0799607998252873

2023-04-18 09:01:59.366161: step 416/650 (epoch 32/50), loss = 1809.216922 (11.399 sec/batch), lr: 0.000349
Evaluating on dev set...
..epoch 32: train_loss = 1809.216922
domain 0 NDCG: 0.05135963139578696 HIT: 0.08490566037735849
domain 1 NDCG: 0.026098183128770935 HIT: 0.061855670103092786
0.0799607998252873

2023-04-18 09:02:13.275894: step 429/650 (epoch 33/50), loss = 1799.657222 (13.273 sec/batch), lr: 0.000349
Evaluating on dev set...
..epoch 33: train_loss = 1799.657222
domain 0 NDCG: 0.06098192990467821 HIT: 0.12264150943396226
domain 1 NDCG: 0.05446266592378483 HIT: 0.12371134020618557
0.0799607998252873

2023-04-18 09:02:25.939269: step 442/650 (epoch 34/50), loss = 1807.855949 (11.972 sec/batch), lr: 0.000349
Evaluating on dev set...
..epoch 34: train_loss = 1807.855949
domain 0 NDCG: 0.045585395930079965 HIT: 0.12264150943396226
domain 1 NDCG: 0.047133213770790126 HIT: 0.09278350515463918
0.0799607998252873

2023-04-18 09:02:37.002347: step 455/650 (epoch 35/50), loss = 1809.305420 (10.558 sec/batch), lr: 0.000314
Evaluating on dev set...
..epoch 35: train_loss = 1809.305420
domain 0 NDCG: 0.057092365631366125 HIT: 0.14150943396226415
domain 1 NDCG: 0.04631905731873289 HIT: 0.0979381443298969
0.0799607998252873

2023-04-18 09:02:48.074499: step 468/650 (epoch 36/50), loss = 1818.461022 (10.582 sec/batch), lr: 0.000314
Evaluating on dev set...
..epoch 36: train_loss = 1818.461022
domain 0 NDCG: 0.05249294444081662 HIT: 0.10377358490566038
domain 1 NDCG: 0.03416083025011563 HIT: 0.07731958762886598
0.0799607998252873

2023-04-18 09:02:59.423888: step 481/650 (epoch 37/50), loss = 1803.130346 (10.833 sec/batch), lr: 0.000282
Evaluating on dev set...
..epoch 37: train_loss = 1803.130346
domain 0 NDCG: 0.039506271254400725 HIT: 0.08490566037735849
domain 1 NDCG: 0.036409852760753744 HIT: 0.08762886597938144
0.0799607998252873

2023-04-18 09:03:12.855848: step 494/650 (epoch 38/50), loss = 1813.615742 (12.906 sec/batch), lr: 0.000254
Evaluating on dev set...
..epoch 38: train_loss = 1813.615742
domain 0 NDCG: 0.02486643895784195 HIT: 0.05660377358490566
domain 1 NDCG: 0.04967543817542675 HIT: 0.10309278350515463
0.0799607998252873

2023-04-18 09:03:22.864694: step 507/650 (epoch 39/50), loss = 1805.648473 (9.572 sec/batch), lr: 0.000229
Evaluating on dev set...
..epoch 39: train_loss = 1805.648473
domain 0 NDCG: 0.03765374164713729 HIT: 0.07547169811320754
domain 1 NDCG: 0.03554057341030703 HIT: 0.08762886597938144
0.0799607998252873

2023-04-18 09:03:32.817811: step 520/650 (epoch 40/50), loss = 1810.515292 (9.499 sec/batch), lr: 0.000229
Evaluating on dev set...
..epoch 40: train_loss = 1810.515292
domain 0 NDCG: 0.07874120685408421 HIT: 0.1792452830188679
domain 1 NDCG: 0.06907423954549459 HIT: 0.13402061855670103
0.0799607998252873

2023-04-18 09:03:43.174349: step 533/650 (epoch 41/50), loss = 1811.716709 (9.829 sec/batch), lr: 0.000229
Evaluating on dev set...
..epoch 41: train_loss = 1811.716709
domain 0 NDCG: 0.03108713983106369 HIT: 0.08490566037735849
domain 1 NDCG: 0.03898493929821764 HIT: 0.08247422680412371
0.0799607998252873

2023-04-18 09:03:53.044064: step 546/650 (epoch 42/50), loss = 1794.305794 (9.390 sec/batch), lr: 0.000206
Evaluating on dev set...
..epoch 42: train_loss = 1794.305794
domain 0 NDCG: 0.054034720773572485 HIT: 0.11320754716981132
domain 1 NDCG: 0.04380987001788483 HIT: 0.10309278350515463
0.0799607998252873

2023-04-18 09:04:02.763911: step 559/650 (epoch 43/50), loss = 1805.836023 (9.289 sec/batch), lr: 0.000206
Evaluating on dev set...
..epoch 43: train_loss = 1805.836023
domain 0 NDCG: 0.035375129540870805 HIT: 0.08490566037735849
domain 1 NDCG: 0.04721238148579412 HIT: 0.10824742268041238
0.0799607998252873

2023-04-18 09:04:12.970258: step 572/650 (epoch 44/50), loss = 1808.553086 (9.778 sec/batch), lr: 0.000185
Evaluating on dev set...
..epoch 44: train_loss = 1808.553086
domain 0 NDCG: 0.04058063094597769 HIT: 0.10377358490566038
domain 1 NDCG: 0.0386074951487303 HIT: 0.08762886597938144
0.0799607998252873

2023-04-18 09:04:22.991055: step 585/650 (epoch 45/50), loss = 1812.176046 (9.604 sec/batch), lr: 0.000185
Evaluating on dev set...
..epoch 45: train_loss = 1812.176046
domain 0 NDCG: 0.05244999855940859 HIT: 0.10377358490566038
domain 1 NDCG: 0.06109007389612316 HIT: 0.12371134020618557
0.0799607998252873

2023-04-18 09:04:32.697867: step 598/650 (epoch 46/50), loss = 1791.413161 (9.280 sec/batch), lr: 0.000185
Evaluating on dev set...
..epoch 46: train_loss = 1791.413161
domain 0 NDCG: 0.06018226548943473 HIT: 0.14150943396226415
domain 1 NDCG: 0.03560103540541559 HIT: 0.06701030927835051
0.0799607998252873

2023-04-18 09:04:42.424334: step 611/650 (epoch 47/50), loss = 1818.031753 (9.312 sec/batch), lr: 0.000185
Evaluating on dev set...
..epoch 47: train_loss = 1818.031753
domain 0 NDCG: 0.04040105495451181 HIT: 0.08490566037735849
domain 1 NDCG: 0.053351828087401874 HIT: 0.11855670103092783
0.0799607998252873

2023-04-18 09:04:52.102835: step 624/650 (epoch 48/50), loss = 1822.640680 (9.266 sec/batch), lr: 0.000167
Evaluating on dev set...
..epoch 48: train_loss = 1822.640680
domain 0 NDCG: 0.047704549716337113 HIT: 0.11320754716981132
domain 1 NDCG: 0.06207839705977441 HIT: 0.12371134020618557
0.0799607998252873

2023-04-18 09:05:01.959184: step 637/650 (epoch 49/50), loss = 1804.686942 (9.405 sec/batch), lr: 0.000167
Evaluating on dev set...
..epoch 49: train_loss = 1804.686942
domain 0 NDCG: 0.03132350714154634 HIT: 0.08490566037735849
domain 1 NDCG: 0.04883825359458432 HIT: 0.09278350515463918
0.0799607998252873

2023-04-18 09:05:11.713131: step 650/650 (epoch 50/50), loss = 1828.273264 (9.332 sec/batch), lr: 0.000150
Evaluating on dev set...
..epoch 50: train_loss = 1828.273264
domain 0 NDCG: 0.06620146506596594 HIT: 0.1509433962264151
domain 1 NDCG: 0.05123706843180916 HIT: 0.1134020618556701
0.0799607998252873