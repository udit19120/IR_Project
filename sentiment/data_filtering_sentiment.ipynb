{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "n8_D3pWcmsUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "path_data = \"/content/gdrive/MyDrive/irProjectDatasets/extracted_data/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUJd--jjnPrj",
        "outputId": "592d2feb-7f31-4feb-d863-0eed09f8d09f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HZB-AaJmlHm"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def pprint(str_,f):\n",
        "    print(str_)\n",
        "    print(str_,end='\\n',file=f)\n",
        "def filter_data(filePath):\n",
        "    data = []\n",
        "    ratings = pd.read_csv(filePath, delimiter=\",\", encoding=\"latin1\")\n",
        "    ratings.columns = ['userId', 'itemId', 'Rating', 'sentiment']\n",
        "    \n",
        "    rate_size_dic_i=ratings.groupby('itemId').size()\n",
        "    choosed_index_del_i=rate_size_dic_i.index[rate_size_dic_i<10]\n",
        "    ratings=ratings[~ratings['itemId'].isin(list(choosed_index_del_i))]\n",
        "    \n",
        "    user_unique=list(ratings['userId'].unique())  \n",
        "    movie_unique=list(ratings['itemId'].unique()) \n",
        "\n",
        "    u=len(user_unique)\n",
        "    i=len(movie_unique)\n",
        "    rating_num = len(ratings)\n",
        "    return u,i,rating_num,user_unique,ratings\n",
        "def get_min_group_size(ratings):\n",
        "    rate_size_dic_u=ratings.groupby('userId').size()\n",
        "    return min(rate_size_dic_u)\n",
        "def reindex_data(ratings1,data_org, dic_u=None):\n",
        "    data = []\n",
        "    if dic_u is None:\n",
        "        user_unique=list(ratings1['userId'].unique())  \n",
        "        user_index=list(range(0,len(user_unique)))\n",
        "        dic_u=dict(zip(user_unique,user_index))\n",
        "    movie_unique1=list(ratings1['itemId'].unique()) \n",
        "    movie_index1=list(range(0,len(movie_unique1)))\n",
        "    dic_m1=dict(zip(movie_unique1,movie_index1))\n",
        "    for element in ratings1.values:\n",
        "        user = element[0]\n",
        "        item = element[1]\n",
        "        # print(element)\n",
        "        sentiment_score = element[3]\n",
        "        data.append((dic_u[element[0]], dic_m1[element[1]], sentiment_score ))\n",
        "    data = sorted(data,key=lambda x:x[0])\n",
        "    return data,dic_u\n",
        "def get_common_data(data1,data2,user_common):\n",
        "    rating_new_1= data1[data1['userId'].isin(common_user)]\n",
        "    rating_new_2 = data2[data2['userId'].isin(common_user)]\n",
        "    return rating_new_1,rating_new_2\n",
        "def get_unique_lenth(ratings):\n",
        "    r_n = len(ratings)\n",
        "    user_unique=list(ratings['userId'].unique())  \n",
        "    movie_unique=list(ratings['itemId'].unique()) \n",
        "    u=len(user_unique)\n",
        "    i=len(movie_unique)\n",
        "    return u,i,r_n\n",
        "def filter_user(ratings1,ratings2):\n",
        "    rate_size_dic_u1=ratings1.groupby('userId').size()\n",
        "    rate_size_dic_u2=ratings2.groupby('userId').size()\n",
        "    choosed_index_del_u1=rate_size_dic_u1.index[rate_size_dic_u1<5]\n",
        "    choosed_index_del_u2=rate_size_dic_u2.index[rate_size_dic_u2<5]\n",
        "    ratings1=ratings1[~ratings1['userId'].isin(list(choosed_index_del_u1)+list(choosed_index_del_u2))]\n",
        "    ratings2=ratings2[~ratings2['userId'].isin(list(choosed_index_del_u1)+list(choosed_index_del_u2))]\n",
        "    return ratings1,ratings2\n",
        "def write_to_txt(data,file):\n",
        "    f = open(file,'w+')\n",
        "    for i in data:\n",
        "        line = '\\t'.join([str(x) for x in i])+'\\n'\n",
        "        f.write(line)\n",
        "    f.close\n",
        "def get_common_user(data1,data2):\n",
        "    common_user = list(set(data1).intersection(set(data2)))\n",
        "    return len(common_user),common_user\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_name_s = 'cell_phones'\n",
        "data_name_t = 'digital_music'"
      ],
      "metadata": {
        "id": "dwHrqyjWnlSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datapath = path_data\n",
        "save_path = path_data\n",
        "\n",
        "save_path_s = save_path + data_name_s+'_'+data_name_t+'/'\n",
        "save_path_t = save_path + data_name_t+'_'+data_name_s+'/'\n",
        "\n",
        "if not os.path.exists(save_path_s):\n",
        "    os.makedirs(save_path_s)\n",
        "if not os.path.exists(save_path_t):\n",
        "    os.makedirs(save_path_t)\n",
        "\n",
        "data_dic = {'sport':'ratings_Sports_and_Outdoors','electronic':'ratings_Electronics',\n",
        "            'cloth':'ratings_Clothing_Shoes_and_Jewelry','cell':'ratings_Cell_Phones_and_Accessories'}\n",
        "filepath1 = datapath + data_name_s +'_user_item_map_unique_sentiment.csv'\n",
        "filepath2 = datapath + data_name_t +'_user_item_map_unique_sentiment.csv'\n",
        "\n",
        "save_file1 = save_path_s + 'new_reindex_sentiment.txt'\n",
        "save_file2 = save_path_t+ 'new_reindex_sentiment.txt'\n",
        "\n",
        "f_path= save_path_t+'%s_%s_data_info.txt'%(data_name_s,data_name_t)\n",
        "f = open(f_path,'w+')\n",
        "u_num,i_num,r_num,user_unique,data = filter_data(filepath1)\n",
        "u_num2,i_num2,r_num2,user_unique2,data2 = filter_data(filepath2)\n",
        "\n",
        "\n",
        "c_n, common_user =get_common_user(user_unique,user_unique2)\n",
        "pprint('raw_data1 info : %d %d %d'%(u_num,i_num,r_num),f)\n",
        "pprint('raw_data2 info : %d %d %d'%(u_num2,i_num2,r_num2),f)\n",
        "pprint('common user num %d'%c_n,f)\n",
        "new_data_1,new_data_2 =get_common_data(data,data2,common_user)\n",
        "new_data_1,new_data_2 =filter_user(new_data_1,new_data_2)\n",
        "u,i ,r= get_unique_lenth(new_data_1)\n",
        "u2,i2 ,r2= get_unique_lenth(new_data_2)\n",
        "pprint('after common_data1 info : %d %d %d %.6f'%(u,i,r,r/(u*i)),f)\n",
        "pprint('after common_data2 info : %d %d %d %.6f'%(u2,i2,r2,r2/(u2*i2)),f)\n",
        "data1,dic_u = reindex_data(new_data_1, pd.read_csv(filepath1))\n",
        "data2,dic_u2 = reindex_data(new_data_2,pd.read_csv(filepath2), dic_u)\n",
        "min1 = get_min_group_size(new_data_1,)\n",
        "min2 = get_min_group_size(new_data_2)\n",
        "assert dic_u == dic_u2,'user_dic not same'\n",
        "pprint('min user group size is %d %d'%(min1,min2),f)\n",
        "pprint('filter way: user>%d,item>%d'%(5,10),f)\n",
        "# print('after common_data+filter item info : %d %d %d'%(u,i,r))\n",
        "# print('after common_data2+filter item info : %d %d %d'%(u2,i2,r2))\n",
        "write_to_txt(data1,save_file1)\n",
        "write_to_txt(data2,save_file2)\n",
        "pprint('write data finished!',f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxvEblCmnYwW",
        "outputId": "c3a399e3-3022-4103-95ba-85a89efc5690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "raw_data1 info : 157155 25661 974706\n",
            "raw_data2 info : 16410 4632 101612\n",
            "common user num 1473\n",
            "after common_data1 info : 713 4759 6658 0.001962\n",
            "after common_data2 info : 713 3335 8202 0.003449\n"
          ]
        }
      ]
    }
  ]
}